"""
formatter/ai_refiner.py ‚Äî Deepseek API integration cho --ai-clean v√† --ai-summary
"""
import re
from typing import Optional

from config import (
    AI_MAX_CHUNK_CHARS,
    DEEPSEEK_API_KEY,
    DEEPSEEK_BASE_URL,
    DEEPSEEK_MODEL,
)
from utils.logger import setup_logger

logger = setup_logger()

_client = None


def _get_client():
    """Lazy init OpenAI client v·ªõi Deepseek endpoint."""
    global _client
    if _client is None:
        if not DEEPSEEK_API_KEY:
            raise ValueError("DEEPSEEK_API_KEY ch∆∞a ƒë∆∞·ª£c set trong .env")
        try:
            from openai import OpenAI
            _client = OpenAI(
                api_key=DEEPSEEK_API_KEY,
                base_url=DEEPSEEK_BASE_URL,
            )
        except ImportError:
            raise ImportError("C·∫ßn c√†i openai: pip install openai")
    return _client


def _call_api(system_prompt: str, user_content: str) -> str:
    """G·ªçi Deepseek API v·ªõi error handling."""
    client = _get_client()
    response = client.chat.completions.create(
        model=DEEPSEEK_MODEL,
        messages=[
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": user_content},
        ],
        temperature=0.1,  # √çt creative, nhi·ªÅu consistent
        max_tokens=4096,
    )
    return response.choices[0].message.content or ""


def _chunk_text(text: str, max_chars: int = AI_MAX_CHUNK_CHARS) -> list[str]:
    """Chia text th√†nh c√°c chunk, ∆∞u ti√™n c·∫Øt t·∫°i paragraph boundaries."""
    if len(text) <= max_chars:
        return [text]

    chunks = []
    paragraphs = text.split("\n\n")
    current_chunk = ""

    for para in paragraphs:
        if len(current_chunk) + len(para) + 2 > max_chars:
            if current_chunk:
                chunks.append(current_chunk.strip())
            current_chunk = para
        else:
            current_chunk = f"{current_chunk}\n\n{para}" if current_chunk else para

    if current_chunk:
        chunks.append(current_chunk.strip())

    return chunks


# ---------------------------------------------------------------------------
# --ai-clean: L√†m s·∫°ch v√† chu·∫©n h√≥a Markdown
# ---------------------------------------------------------------------------

_CLEAN_SYSTEM_PROMPT = """B·∫°n l√† m·ªôt Markdown formatter chuy√™n nghi·ªáp.
Task: Nh·∫≠n Markdown th√¥ ƒë∆∞·ª£c extract t·ª´ HTML, tr·∫£ v·ªÅ Markdown ƒë√£ ƒë∆∞·ª£c chu·∫©n h√≥a.

Quy t·∫Øc QUAN TR·ªåNG:
1. GI·ªÆ NGUY√äN to√†n b·ªô n·ªôi dung, kh√¥ng th√™m/b·ªõt th√¥ng tin.
2. Fix l·ªói th·ª•t l·ªÅ code blocks (ƒë·∫£m b·∫£o d√πng ``` kh√¥ng ph·∫£i indent).
3. Chu·∫©n h√≥a b·∫£ng Markdown (| col | col |).
4. X√≥a c√°c k√Ω t·ª± noise: \xa0, ‚Äã (zero-width space), k√Ω t·ª± kh√¥ng in ƒë∆∞·ª£c.
5. ƒê·∫£m b·∫£o c√≥ blank line tr∆∞·ªõc/sau m·ªói code block v√† table.
6. Ch·ªâ tr·∫£ v·ªÅ Markdown, KH√îNG gi·∫£i th√≠ch th√™m g√¨."""


def clean_markdown(text: str, url: str = "") -> str:
    """
    D√πng Deepseek AI ƒë·ªÉ chu·∫©n h√≥a Markdown (--ai-clean).
    T·ª± ƒë·ªông chunk n·∫øu content l·ªõn.
    Fallback v·ªÅ text g·ªëc n·∫øu API l·ªói.
    """
    if not text.strip():
        return text

    try:
        chunks = _chunk_text(text)
        cleaned_chunks = []

        for i, chunk in enumerate(chunks):
            if len(chunks) > 1:
                logger.info(f"    ü§ñ AI clean chunk {i+1}/{len(chunks)}...")
            result = _call_api(_CLEAN_SYSTEM_PROMPT, chunk)
            cleaned_chunks.append(result)

        return "\n\n".join(cleaned_chunks)

    except Exception as e:
        logger.warning(f"  ‚ö†Ô∏è  AI clean th·∫•t b·∫°i cho {url}: {e} ‚Äî d√πng k·∫øt qu·∫£ th√¥.")
        return text  # Fallback v·ªÅ text g·ªëc


# ---------------------------------------------------------------------------
# --ai-summary: T·∫°o t√≥m t·∫Øt ng·∫Øn (~50 t·ª´) ƒë·∫ßu m·ªói trang
# ---------------------------------------------------------------------------

_SUMMARY_SYSTEM_PROMPT = """B·∫°n l√† assistant t√≥m t·∫Øt t√†i li·ªáu k·ªπ thu·∫≠t.
Task: ƒê·ªçc n·ªôi dung trang web v√† vi·∫øt t√≥m t·∫Øt ng·∫Øn g·ªçn b·∫±ng ti·∫øng Vi·ªát.

Quy t·∫Øc:
1. T√≥m t·∫Øt KH√îNG qu√° 60 t·ª´.
2. T·∫≠p trung v√†o n·ªôi dung ch√≠nh, kh√¥ng ƒë·ªÅ c·∫≠p navigation hay UI.
3. Vi·∫øt d·∫°ng c√¢u ƒë∆°n, r√µ r√†ng.
4. Ch·ªâ tr·∫£ v·ªÅ ƒëo·∫°n t√≥m t·∫Øt, KH√îNG ti√™u ƒë·ªÅ, KH√îNG gi·∫£i th√≠ch th√™m."""


def summarize_page(title: str, content: str, url: str = "") -> Optional[str]:
    """
    T·∫°o t√≥m t·∫Øt ~50 t·ª´ cho m·ªôt trang (--ai-summary).
    Ch·ªâ d√πng 3000 k√Ω t·ª± ƒë·∫ßu ƒë·ªÉ t√≥m t·∫Øt (ti·∫øt ki·ªám tokens).
    Fallback v·ªÅ None n·∫øu API l·ªói.
    """
    if not content.strip():
        return None

    # Gi·ªõi h·∫°n input ƒë·ªÉ ti·∫øt ki·ªám tokens
    preview = content[:3000]
    user_content = f"Ti√™u ƒë·ªÅ: {title}\n\nN·ªôi dung:\n{preview}"

    try:
        result = _call_api(_SUMMARY_SYSTEM_PROMPT, user_content)
        summary = result.strip()
        # C·∫Øt n·∫øu AI tr·∫£ v·ªÅ qu√° d√†i
        words = summary.split()
        if len(words) > 70:
            summary = " ".join(words[:60]) + "..."
        return summary
    except Exception as e:
        logger.warning(f"  ‚ö†Ô∏è  AI summary th·∫•t b·∫°i cho {url}: {e}")
        return None
